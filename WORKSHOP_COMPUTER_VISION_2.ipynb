{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNFwT9uWOscTZrq5o3rPi87",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fadel11-hub/WORKSHOP-MSIB-5/blob/main/WORKSHOP_COMPUTER_VISION_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Convolutional Neural Network(CNN)"
      ],
      "metadata": {
        "id": "UpmLFJZ61A8l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import library"
      ],
      "metadata": {
        "id": "sp4FyN0GXK1r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I43Jk35AHNjn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset"
      ],
      "metadata": {
        "id": "22ss-xazZSVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n",
        "\n",
        "local_zip = './horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('./horse-or-human')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8yWAlVpov8H",
        "outputId": "d88e26d9-4ab3-424d-dc9a-ad35a4615072"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-28 07:25:44--  https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.207, 74.125.195.207, 172.253.117.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘horse-or-human.zip’\n",
            "\n",
            "horse-or-human.zip  100%[===================>] 142.65M   237MB/s    in 0.6s    \n",
            "\n",
            "2024-01-28 07:25:44 (237 MB/s) - ‘horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Horse or Human validation dataset\n",
        "!wget -q -P /content/ https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip\n",
        "\n",
        "val_local_zip = './validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(val_local_zip, 'r')\n",
        "zip_ref.extractall('validation-horse-or-human')\n",
        "zip_ref.close()\n"
      ],
      "metadata": {
        "id": "CFUuMVoQxOO1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory with our training horse pictures\n",
        "train_horse_dir = os.path.join('./horse-or-human/horses')\n",
        "\n",
        "# Directory with our training human pictures\n",
        "train_human_dir = os.path.join('./horse-or-human/humans')\n",
        "\n",
        "# Directory with validation horse pictures\n",
        "validation_horses_dir = os.path.join('validation-horse-or-human/horses')\n",
        "# Directory with validation human pictures\n",
        "validation_humans_dir = os.path.join('validation-horse-or-human/humans')"
      ],
      "metadata": {
        "id": "hhqKsrKKo4ZH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/'\n",
        "\n",
        "print(\"Contents of base directory:\")\n",
        "print(os.listdir(base_dir))\n",
        "\n",
        "print(\"\\nContents of train directory:\")\n",
        "print(os.listdir(f'{base_dir}/horse-or-human'))\n",
        "\n",
        "print(\"\\nContents of validation directory:\")\n",
        "print(os.listdir(f'{base_dir}/validation-horse-or-human'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-_purxzqx5C",
        "outputId": "a7859254-50e7-4431-b1e0-b55c72259fd7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of base directory:\n",
            "['.config', 'horse-or-human.zip', 'horse-or-human', 'validation-horse-or-human', 'validation-horse-or-human.zip', 'sample_data']\n",
            "\n",
            "Contents of train directory:\n",
            "['humans', 'horses']\n",
            "\n",
            "Contents of validation directory:\n",
            "['humans', 'horses']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('total training horses images :', len(os.listdir(  train_horse_dir ) ))\n",
        "print('total training humans images :', len(os.listdir(  train_human_dir ) ))\n",
        "\n",
        "print('total validation horses images :', len(os.listdir( validation_horses_dir ) ))\n",
        "print('total validation humans images :', len(os.listdir( validation_humans_dir ) ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hv1vpTurTtZ",
        "outputId": "e2d4edb5-dfa4-45fe-f4f0-9f1a92a1552d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training horses images : 500\n",
            "total training humans images : 527\n",
            "total validation horses images : 128\n",
            "total validation humans images : 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image preprocessing"
      ],
      "metadata": {
        "id": "RIhzk_8dZWGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255)\n",
        "\n"
      ],
      "metadata": {
        "id": "XXjUpiCTZHR1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ImageDataGenerator.flow_from_directory() adalah metode yang digunakan untuk menghasilkan generator data dari direktori.\n",
        "\n",
        "\n",
        "*   ./horse-or-human/ adalah direktori yang berisi data latih.\n",
        "*   target_size=(300, 300) adalah ukuran gambar yang diinginkan.\n",
        "*   batch_size=128 adalah jumlah gambar yang akan dimuat dalam satu batch.\n",
        "*   class_mode='binary' adalah mode kelas untuk data latih.\n",
        "\n",
        "Dalam kasus ini, data latih memiliki dua kelas, yaitu kuda dan manusia.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dOIi27_FusEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        './horse-or-human/',  # direktori data latih\n",
        "        target_size=(300, 300),  # mengubah resolusi seluruh gambar menjadi 300X300 piksel\n",
        "        batch_size=128,\n",
        "        class_mode='binary' # karena ini merupakan masalah klasifikasi 2 kelas, gunakan class_mode = 'binary'\n",
        "        )\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        './validation-horse-or-human/', # direktori data validasi\n",
        "        target_size=(300, 300), # mengubah resolusi seluruh gambar menjadi 3000x300 piksel\n",
        "        batch_size=20,\n",
        "        class_mode='binary',# karena ini merupakan masalah klasifikasi 2 kelas gunakan class_mode = 'binary'\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVUcx9aIZZpZ",
        "outputId": "9ecb140c-33b9-4b74-aa6b-a516d89e88d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fungsi dari Code ini\n",
        "1. print(train_generator.class_indices)\n",
        "\n",
        "Baris ini menampilkan kamus yang memetakan nama kelas ke indeks numerik yang digunakan oleh generator data untuk mewakili setiap kelas.\n",
        "Contoh output:\n",
        "{'horses': 0, 'humans': 1}\n",
        "Pada output ini, kelas \"horses\" memiliki indeks 0, dan kelas \"humans\" memiliki indeks 1.\n",
        "\n",
        "2. labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "Baris ini membuat sebuah string yang berisi nama-nama kelas, dipisahkan oleh newline (\\n).\n",
        "Prosesnya:\n",
        "Mengambil nama-nama kelas dari kunci dalam kamus train_generator.class_indices.\n",
        "Mengurutkan nama-nama kelas secara alfabetis.\n",
        "Menggabungkan nama-nama kelas yang sudah diurutkan dengan newline sebagai pemisah.\n",
        "\n"
      ],
      "metadata": {
        "id": "raXJwajcvPs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "# with open('/content/drive/MyDrive/Bangkit_Academy/WOKRHOP MSIB 5/Dataset/label.txt', 'w') as f:\n",
        "  # f.write(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS_B3wvnZtwc",
        "outputId": "cdf62818-9281-4b31-b456-ccd74d0c74c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'horses': 0, 'humans': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model"
      ],
      "metadata": {
        "id": "LmbtBY3qm7wX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Berikut penjelasan kode tersebut secara detail dalam bahasa Indonesia:**\n",
        "\n",
        "**1. `model = tf.keras.models.Sequential(...)`**\n",
        "\n",
        "- Baris ini membuat model baru bernama `model` dengan struktur Sequential, artinya lapisan model disusun secara berurutan.\n",
        "\n",
        "**2. `tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300,300,3))`**\n",
        "\n",
        "- Lapisan Convolutional 2D pertama dengan:\n",
        "    - 16 filter (kernel) berukuran 3x3\n",
        "    - Fungsi aktivasi ReLU (Rectified Linear Unit)\n",
        "    - Input shape sebesar 300x300 piksel dengan 3 saluran warna (RGB)\n",
        "\n",
        "**3. `tf.keras.layers.MaxPooling2D(2,2)`**\n",
        "\n",
        "- Lapisan Max Pooling 2D dengan ukuran pool 2x2 untuk mengurangi dimensi spasial dan menangkap fitur-fitur penting.\n",
        "\n",
        "**dan seterusnya sampai dengan lapisan Flatten**\n",
        "\n",
        "**10. `tf.keras.layers.Flatten()`**\n",
        "\n",
        "- Lapisan Flatten untuk mengubah output tensor 3D dari lapisan Convolutional menjadi tensor 1D (vektor) agar dapat diproses oleh lapisan Dense.\n",
        "\n",
        "**11. `tf.keras.layers.Dense(64, activation='relu')`**\n",
        "\n",
        "- Lapisan Dense dengan 64 neuron dan aktivasi ReLU untuk mempelajari representasi fitur yang lebih kompleks.\n",
        "\n",
        "**12. `tf.keras.layers.Dense(1, activation='sigmoid')`**\n",
        "\n",
        "- Lapisan Dense output dengan 1 neuron dan aktivasi sigmoid untuk menghasilkan probabilitas antara 0 dan 1, cocok untuk masalah klasifikasi biner (dua kelas).\n",
        "\n",
        "**Kesimpulan:**\n",
        "\n",
        "- Kode ini mendefinisikan model klasifikasi gambar berbasis CNN (Convolutional Neural Network) yang terdiri dari beberapa lapisan Convolutional dan Max Pooling, diikuti oleh lapisan Dense untuk klasifikasi akhir.\n",
        "- Model ini akan belajar mengekstraksi fitur-fitur penting dari gambar untuk membedakan antara dua kelas.\n"
      ],
      "metadata": {
        "id": "PjjWkjhZoVCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu',input_shape=(300,300,3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "XS2KYT5haALE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hXtkrR8n4A2",
        "outputId": "740e72cf-af2b-41d2-abfe-12afd9410760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 149, 149, 16)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 73, 73, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 35, 35, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 33, 33, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1048640   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1109217 (4.23 MB)\n",
            "Trainable params: 1109217 (4.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Berikut penjelasan kode tersebut secara detail:**\n",
        "\n",
        "**1. `model.compile(...)`**\n",
        "\n",
        "- Baris ini mempersiapkan model untuk pelatihan dengan menentukan fungsi loss, optimizer, dan metrik yang akan digunakan.\n",
        "\n",
        "**2. `loss='binary_crossentropy'`**\n",
        "\n",
        "- Menentukan fungsi loss yang mengukur perbedaan antara prediksi model dan label sebenarnya untuk setiap contoh. Dalam kasus klasifikasi biner, `binary_crossentropy` adalah fungsi loss yang umum digunakan.\n",
        "\n",
        "**3. `optimizer=tf.optimizers.RMSprop(learning_rate=0.001)`**\n",
        "\n",
        "- Menentukan algoritma optimizer yang digunakan untuk memperbarui bobot model selama pelatihan.\n",
        "- `tf.optimizers.RMSprop` adalah optimizer yang sering digunakan untuk model deep learning.\n",
        "- `learning_rate=0.001` mengatur seberapa besar perubahan yang akan dilakukan pada bobot model pada setiap langkah pelatihan.\n",
        "\n",
        "**4. `metrics=['accuracy']`**\n",
        "\n",
        "- Menentukan metrik yang akan digunakan untuk mengevaluasi performa model selama pelatihan dan validasi.\n",
        "- Dalam kasus ini, `accuracy` (akurasi) digunakan untuk mengukur persentase prediksi yang benar.\n"
      ],
      "metadata": {
        "id": "Rtsk9dhwpC_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.optimizers.RMSprop(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mCUQaWPloClq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=7\n",
        "# latih model dengan model.fit\n",
        "history = model.fit(\n",
        "            train_generator,\n",
        "            epochs=epochs, # tambahkan epochs jika akurasi model belum optimal\n",
        "            validation_data=validation_generator # menampilkan akurasi pengujian data validasi\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSX1cBkUohFa",
        "outputId": "fd13adb7-2096-4454-f5f8-161a3d72a2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "9/9 [==============================] - 18s 962ms/step - loss: 0.8049 - accuracy: 0.4800 - val_loss: 0.6909 - val_accuracy: 0.5000\n",
            "Epoch 2/7\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.6741 - accuracy: 0.5531 - val_loss: 0.6361 - val_accuracy: 0.5586\n",
            "Epoch 3/7\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.6659 - accuracy: 0.6154 - val_loss: 0.6219 - val_accuracy: 0.6484\n",
            "Epoch 4/7\n",
            "9/9 [==============================] - 9s 959ms/step - loss: 0.5633 - accuracy: 0.7478 - val_loss: 0.7062 - val_accuracy: 0.6836\n",
            "Epoch 5/7\n",
            "9/9 [==============================] - 10s 987ms/step - loss: 0.5807 - accuracy: 0.8423 - val_loss: 0.8355 - val_accuracy: 0.8008\n",
            "Epoch 6/7\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.1784 - accuracy: 0.9435 - val_loss: 1.4920 - val_accuracy: 0.7734\n",
            "Epoch 7/7\n",
            "9/9 [==============================] - 9s 1s/step - loss: 0.1692 - accuracy: 0.9279 - val_loss: 2.6377 - val_accuracy: 0.6797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "uLR6vwtl-112"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # Memprediksi Image\n",
        "  path = '/content/' + fn\n",
        "  img = load_img(path, target_size=(300, 300))\n",
        "  x = img_to_array(img)\n",
        "  x /= 255\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a human\")\n",
        "  else:\n",
        "    print(fn + \" is a horse\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "QezBe7C0qV4L",
        "outputId": "55dde2a5-4b71-4637-85fe-739058d179ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-534c16b7-6b46-4f40-8b82-ee2a8b6224b0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-534c16b7-6b46-4f40-8b82-ee2a8b6224b0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tranfer learning & Augmentation"
      ],
      "metadata": {
        "id": "rgC_HK6L-4-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Preprocessing"
      ],
      "metadata": {
        "id": "RO5ZS7_BEng4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Penjelasan kode ImageDataGenerator :**\n",
        "\n",
        "**1. `train_datagen_2 = ImageDataGenerator(...)`**\n",
        "\n",
        "- Baris ini membuat sebuah objek ImageDataGenerator bernama `train_datagen_2` yang akan digunakan untuk menghasilkan versi gambar yang telah dimodifikasi untuk meningkatkan variasi dalam dataset Anda.\n",
        "\n",
        "**2. `rescale=1./255`**\n",
        "\n",
        "- Mengubah nilai piksel gambar dari rentang 0-255 menjadi 0-1. Ini penting karena model pembelajaran mesin seringkali bekerja lebih baik dengan nilai input yang dinormalisasi.\n",
        "\n",
        "**3. `rotation_range=20`**\n",
        "\n",
        "- Merotasi gambar secara acak hingga 20 derajat ke kiri atau kanan.\n",
        "\n",
        "**4. `horizontal_flip=True`**\n",
        "\n",
        "- Membalik gambar secara horizontal secara acak.\n",
        "\n",
        "**5. `shear_range=0.2`**\n",
        "\n",
        "- Memiringkan gambar secara acak hingga 20% secara horizontal.\n",
        "\n",
        "**Kesimpulan:**\n",
        "\n",
        "- Kode ini menyiapkan generator data yang akan menghasilkan versi gambar yang telah dimodifikasi secara acak untuk meningkatkan variasi dalam dataset Anda.\n",
        "- Modifikasi ini dapat membantu model pembelajaran mesin untuk menjadi lebih robust (tahan) terhadap perubahan-perubahan kecil pada gambar dan untuk menggeneralisasi lebih baik pada data baru.\n",
        "- Pemisahan set validasi juga penting untuk memastikan model tidak mengalami overfitting (terlalu menyesuaikan dengan data latih).\n"
      ],
      "metadata": {
        "id": "6RqsBmR-v2ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen_2 = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    )\n",
        "\n",
        "validation_datagen_2 = ImageDataGenerator(rescale=1./255)\n",
        "\n"
      ],
      "metadata": {
        "id": "orUTAeyoonEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generatort_aug = train_datagen_2.flow_from_directory(\n",
        "        './horse-or-human/',  # direktori data latih\n",
        "        target_size=(300, 300),\n",
        "        batch_size=4,\n",
        "        class_mode='binary',\n",
        "        )\n",
        "\n",
        "validation_generatortf = validation_datagen_2.flow_from_directory(\n",
        "        './validation-horse-or-human/', # direktori data validasi\n",
        "        target_size=(300, 300),\n",
        "        batch_size=4,\n",
        "        class_mode='binary',\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VG6bGlFO_XlH",
        "outputId": "e7ebd5c8-50fc-46a0-abb9-ebc13edaed1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Transfer Learning"
      ],
      "metadata": {
        "id": "J-qoXr_ZEsj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
        "\n",
        "Baris ini memuat model MobileNetV2 yang sudah terlatih sebelumnya dari TensorFlow Hub.\n",
        "Penjelasan:\n",
        "* tf.keras.applications.MobileNetV2: fungsi untuk memuat model MobileNetV2.\n",
        "input_shape=IMG_SHAPE: menentukan ukuran gambar input yang sesuai dengan yang telah kita definisikan sebelumnya.\n",
        "\n",
        "* include_top=False: menghilangkan lapisan teratas dari model, yang biasanya digunakan untuk klasifikasi 1000 kelas ImageNet. Kita akan menambahkan lapisan kita sendiri untuk tugas klasifikasi spesifik yang kita perlukan.\n",
        "\n",
        "* weights='imagenet': menggunakan bobot yang telah dilatih sebelumnya pada dataset ImageNet yang besar, berisi jutaan gambar. Bobot ini sudah mengandung pengetahuan umum tentang fitur-fitur visual yang dapat membantu dalam berbagai tugas klasifikasi gambar.\n",
        "\n",
        "2. base_model.trainable = False\n",
        "\n",
        "* Baris ini menetapkan model MobileNetV2 menjadi tidak dapat dilatih. Artinya, selama pelatihan model, bobot dalam model MobileNetV2 tidak akan diubah. Hal ini dilakukan untuk mempercepat pelatihan dan mencegah overfitting, karena model dasar sudah memiliki pengetahuan yang cukup baik tentang fitur-fitur visual"
      ],
      "metadata": {
        "id": "fATXhtGU2y-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (300, 300, 3)\n",
        "\n",
        "# Buat model dasar dari MobileNet V2 yang telah dilatih sebelumnya\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False,\n",
        "                                              weights='imagenet')\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGThGleC_72z",
        "outputId": "dd10c338-1e08-4100-ba5a-a8b75902e76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVwFLVx4__ns",
        "outputId": "a59d4762-e40a-4fa9-aaba-0dab779f6a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mobilenetv2_1.00_224\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 300, 300, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)              (None, 150, 150, 32)         864       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalizati  (None, 150, 150, 32)         128       ['Conv1[0][0]']               \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)           (None, 150, 150, 32)         0         ['bn_Conv1[0][0]']            \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (D  (None, 150, 150, 32)         288       ['Conv1_relu[0][0]']          \n",
            " epthwiseConv2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN  (None, 150, 150, 32)         128       ['expanded_conv_depthwise[0][0\n",
            "  (BatchNormalization)                                              ]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_re  (None, 150, 150, 32)         0         ['expanded_conv_depthwise_BN[0\n",
            " lu (ReLU)                                                          ][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv_project (Con  (None, 150, 150, 16)         512       ['expanded_conv_depthwise_relu\n",
            " v2D)                                                               [0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (  (None, 150, 150, 16)         64        ['expanded_conv_project[0][0]'\n",
            " BatchNormalization)                                                ]                             \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)     (None, 150, 150, 96)         1536      ['expanded_conv_project_BN[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNo  (None, 150, 150, 96)         384       ['block_1_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)  (None, 150, 150, 96)         0         ['block_1_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D  (None, 151, 151, 96)         0         ['block_1_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_1_depthwise (Depthwi  (None, 75, 75, 96)           864       ['block_1_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (Batc  (None, 75, 75, 96)           384       ['block_1_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (Re  (None, 75, 75, 96)           0         ['block_1_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)    (None, 75, 75, 24)           2304      ['block_1_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchN  (None, 75, 75, 24)           96        ['block_1_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)     (None, 75, 75, 144)          3456      ['block_1_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNo  (None, 75, 75, 144)          576       ['block_2_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)  (None, 75, 75, 144)          0         ['block_2_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_depthwise (Depthwi  (None, 75, 75, 144)          1296      ['block_2_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (Batc  (None, 75, 75, 144)          576       ['block_2_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (Re  (None, 75, 75, 144)          0         ['block_2_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)    (None, 75, 75, 24)           3456      ['block_2_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchN  (None, 75, 75, 24)           96        ['block_2_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_add (Add)           (None, 75, 75, 24)           0         ['block_1_project_BN[0][0]',  \n",
            "                                                                     'block_2_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)     (None, 75, 75, 144)          3456      ['block_2_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNo  (None, 75, 75, 144)          576       ['block_3_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)  (None, 75, 75, 144)          0         ['block_3_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D  (None, 77, 77, 144)          0         ['block_3_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_3_depthwise (Depthwi  (None, 38, 38, 144)          1296      ['block_3_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (Batc  (None, 38, 38, 144)          576       ['block_3_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (Re  (None, 38, 38, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)    (None, 38, 38, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchN  (None, 38, 38, 32)           128       ['block_3_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)     (None, 38, 38, 192)          6144      ['block_3_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNo  (None, 38, 38, 192)          768       ['block_4_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)  (None, 38, 38, 192)          0         ['block_4_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_depthwise (Depthwi  (None, 38, 38, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (Batc  (None, 38, 38, 192)          768       ['block_4_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (Re  (None, 38, 38, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)    (None, 38, 38, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchN  (None, 38, 38, 32)           128       ['block_4_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_add (Add)           (None, 38, 38, 32)           0         ['block_3_project_BN[0][0]',  \n",
            "                                                                     'block_4_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)     (None, 38, 38, 192)          6144      ['block_4_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNo  (None, 38, 38, 192)          768       ['block_5_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)  (None, 38, 38, 192)          0         ['block_5_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_depthwise (Depthwi  (None, 38, 38, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (Batc  (None, 38, 38, 192)          768       ['block_5_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (Re  (None, 38, 38, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)    (None, 38, 38, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchN  (None, 38, 38, 32)           128       ['block_5_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_5_add (Add)           (None, 38, 38, 32)           0         ['block_4_add[0][0]',         \n",
            "                                                                     'block_5_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)     (None, 38, 38, 192)          6144      ['block_5_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNo  (None, 38, 38, 192)          768       ['block_6_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)  (None, 38, 38, 192)          0         ['block_6_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D  (None, 39, 39, 192)          0         ['block_6_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_6_depthwise (Depthwi  (None, 19, 19, 192)          1728      ['block_6_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (Batc  (None, 19, 19, 192)          768       ['block_6_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (Re  (None, 19, 19, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)    (None, 19, 19, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchN  (None, 19, 19, 64)           256       ['block_6_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)     (None, 19, 19, 384)          24576     ['block_6_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNo  (None, 19, 19, 384)          1536      ['block_7_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)  (None, 19, 19, 384)          0         ['block_7_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_depthwise (Depthwi  (None, 19, 19, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (Batc  (None, 19, 19, 384)          1536      ['block_7_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (Re  (None, 19, 19, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)    (None, 19, 19, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchN  (None, 19, 19, 64)           256       ['block_7_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_7_add (Add)           (None, 19, 19, 64)           0         ['block_6_project_BN[0][0]',  \n",
            "                                                                     'block_7_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)     (None, 19, 19, 384)          24576     ['block_7_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNo  (None, 19, 19, 384)          1536      ['block_8_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)  (None, 19, 19, 384)          0         ['block_8_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_depthwise (Depthwi  (None, 19, 19, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (Batc  (None, 19, 19, 384)          1536      ['block_8_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (Re  (None, 19, 19, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)    (None, 19, 19, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchN  (None, 19, 19, 64)           256       ['block_8_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_8_add (Add)           (None, 19, 19, 64)           0         ['block_7_add[0][0]',         \n",
            "                                                                     'block_8_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)     (None, 19, 19, 384)          24576     ['block_8_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNo  (None, 19, 19, 384)          1536      ['block_9_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)  (None, 19, 19, 384)          0         ['block_9_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_depthwise (Depthwi  (None, 19, 19, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (Batc  (None, 19, 19, 384)          1536      ['block_9_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (Re  (None, 19, 19, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)    (None, 19, 19, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchN  (None, 19, 19, 64)           256       ['block_9_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_9_add (Add)           (None, 19, 19, 64)           0         ['block_8_add[0][0]',         \n",
            "                                                                     'block_9_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)    (None, 19, 19, 384)          24576     ['block_9_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchN  (None, 19, 19, 384)          1536      ['block_10_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU  (None, 19, 19, 384)          0         ['block_10_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_10_depthwise (Depthw  (None, 19, 19, 384)          3456      ['block_10_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (Bat  (None, 19, 19, 384)          1536      ['block_10_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (R  (None, 19, 19, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)   (None, 19, 19, 96)           36864     ['block_10_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_10_project_BN (Batch  (None, 19, 19, 96)           384       ['block_10_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)    (None, 19, 19, 576)          55296     ['block_10_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchN  (None, 19, 19, 576)          2304      ['block_11_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU  (None, 19, 19, 576)          0         ['block_11_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_11_depthwise (Depthw  (None, 19, 19, 576)          5184      ['block_11_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (Bat  (None, 19, 19, 576)          2304      ['block_11_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (R  (None, 19, 19, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)   (None, 19, 19, 96)           55296     ['block_11_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_11_project_BN (Batch  (None, 19, 19, 96)           384       ['block_11_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_11_add (Add)          (None, 19, 19, 96)           0         ['block_10_project_BN[0][0]', \n",
            "                                                                     'block_11_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)    (None, 19, 19, 576)          55296     ['block_11_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchN  (None, 19, 19, 576)          2304      ['block_12_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU  (None, 19, 19, 576)          0         ['block_12_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_12_depthwise (Depthw  (None, 19, 19, 576)          5184      ['block_12_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (Bat  (None, 19, 19, 576)          2304      ['block_12_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (R  (None, 19, 19, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)   (None, 19, 19, 96)           55296     ['block_12_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_12_project_BN (Batch  (None, 19, 19, 96)           384       ['block_12_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_12_add (Add)          (None, 19, 19, 96)           0         ['block_11_add[0][0]',        \n",
            "                                                                     'block_12_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)    (None, 19, 19, 576)          55296     ['block_12_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchN  (None, 19, 19, 576)          2304      ['block_13_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU  (None, 19, 19, 576)          0         ['block_13_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2  (None, 21, 21, 576)          0         ['block_13_expand_relu[0][0]']\n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block_13_depthwise (Depthw  (None, 10, 10, 576)          5184      ['block_13_pad[0][0]']        \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (Bat  (None, 10, 10, 576)          2304      ['block_13_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (R  (None, 10, 10, 576)          0         ['block_13_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)   (None, 10, 10, 160)          92160     ['block_13_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_13_project_BN (Batch  (None, 10, 10, 160)          640       ['block_13_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)    (None, 10, 10, 960)          153600    ['block_13_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchN  (None, 10, 10, 960)          3840      ['block_14_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU  (None, 10, 10, 960)          0         ['block_14_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_14_depthwise (Depthw  (None, 10, 10, 960)          8640      ['block_14_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (Bat  (None, 10, 10, 960)          3840      ['block_14_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (R  (None, 10, 10, 960)          0         ['block_14_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)   (None, 10, 10, 160)          153600    ['block_14_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_14_project_BN (Batch  (None, 10, 10, 160)          640       ['block_14_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_14_add (Add)          (None, 10, 10, 160)          0         ['block_13_project_BN[0][0]', \n",
            "                                                                     'block_14_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)    (None, 10, 10, 960)          153600    ['block_14_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchN  (None, 10, 10, 960)          3840      ['block_15_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU  (None, 10, 10, 960)          0         ['block_15_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_15_depthwise (Depthw  (None, 10, 10, 960)          8640      ['block_15_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (Bat  (None, 10, 10, 960)          3840      ['block_15_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (R  (None, 10, 10, 960)          0         ['block_15_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)   (None, 10, 10, 160)          153600    ['block_15_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_15_project_BN (Batch  (None, 10, 10, 160)          640       ['block_15_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_15_add (Add)          (None, 10, 10, 160)          0         ['block_14_add[0][0]',        \n",
            "                                                                     'block_15_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)    (None, 10, 10, 960)          153600    ['block_15_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchN  (None, 10, 10, 960)          3840      ['block_16_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU  (None, 10, 10, 960)          0         ['block_16_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_16_depthwise (Depthw  (None, 10, 10, 960)          8640      ['block_16_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (Bat  (None, 10, 10, 960)          3840      ['block_16_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (R  (None, 10, 10, 960)          0         ['block_16_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)   (None, 10, 10, 320)          307200    ['block_16_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_16_project_BN (Batch  (None, 10, 10, 320)          1280      ['block_16_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)             (None, 10, 10, 1280)         409600    ['block_16_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalizat  (None, 10, 10, 1280)         5120      ['Conv_1[0][0]']              \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " out_relu (ReLU)             (None, 10, 10, 1280)         0         ['Conv_1_bn[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2257984 (8.61 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_aug = tf.keras.models.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "hi9o6LwoAHzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile model dengan 'RMSprop' optimizer loss function 'binary_crossentropy'\n",
        "model_aug.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.optimizers.RMSprop(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qDxWl0v6AbkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model_aug.fit(train_generatort_aug,\n",
        "                      validation_data=validation_generator,\n",
        "                      epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3T4gUdZAhV7",
        "outputId": "f6b81878-b60d-4680-ffb8-a9758775315c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "257/257 [==============================] - 36s 126ms/step - loss: 0.3048 - accuracy: 0.9883 - val_loss: 0.0054 - val_accuracy: 0.9961\n",
            "Epoch 2/3\n",
            "257/257 [==============================] - 28s 111ms/step - loss: 0.0656 - accuracy: 0.9961 - val_loss: 1.3375e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "257/257 [==============================] - 30s 116ms/step - loss: 0.0508 - accuracy: 0.9990 - val_loss: 0.0249 - val_accuracy: 0.9961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "ql0DqFjbE3jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  path = '/content/' + fn\n",
        "  img = load_img(path, target_size=(300, 300))\n",
        "  x = img_to_array(img)\n",
        "  x /= 255\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a human\")\n",
        "  else:\n",
        "    print(fn + \" is a horse\")\n"
      ],
      "metadata": {
        "id": "jEWhV0fgBiwd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "a8cc7635-1985-4a23-f51d-68a136cb23e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-505b615f-7803-463c-b6e1-96331f046d75\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-505b615f-7803-463c-b6e1-96331f046d75\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 20211210132813_IMG_3716.JPG to 20211210132813_IMG_3716.JPG\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "[0.9998436]\n",
            "20211210132813_IMG_3716.JPG is a human\n"
          ]
        }
      ]
    }
  ]
}